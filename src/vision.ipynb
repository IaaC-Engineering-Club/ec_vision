{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "63314bdd",
   "metadata": {},
   "source": [
    "# Computer vision for boat self navigating capabilities"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bceb048c",
   "metadata": {},
   "source": [
    "> This notebook serves as testing ground for all cv objects we create. later these will be transfered to .py files for better performance and usability in main code."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b383ae3b",
   "metadata": {},
   "source": [
    "## imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "b2987566",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2 as cv\n",
    "import numpy as np\n",
    "from PIL import Image\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d526afd9",
   "metadata": {},
   "source": [
    "## Classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "8b458802",
   "metadata": {},
   "outputs": [],
   "source": [
    "class visionNav:\n",
    "    def __init__(self, video=None):\n",
    "        self.video = video\n",
    "        self.image = None\n",
    "        self.hsv_color = None\n",
    "        self.mask_r = None\n",
    "        self.mask_g = None\n",
    "        self.middle_x = None\n",
    "        self.height = None\n",
    "        self.width = None\n",
    "\n",
    "    def text_size(self, width ,direction):\n",
    "        font = cv.FONT_HERSHEY_SIMPLEX\n",
    "        scale = 1.8\n",
    "        thickness = 4\n",
    "        text_size = cv.getTextSize(direction, font, scale, thickness)[0]\n",
    "        cv.putText(self.image, direction, ((width - text_size[0])//2, 50), font, scale, (0, 0, 0), thickness, cv.LINE_AA)\n",
    "\n",
    "    def generate_masks(self):\n",
    "        if self.image is not None:\n",
    "\n",
    "            image_bilateral = cv.bilateralFilter(self.image, 15, 350, 350)\n",
    "            self.hsv_color = cv.cvtColor(image_bilateral, cv.COLOR_BGR2HSV)\n",
    "\n",
    "            #green colorspace\n",
    "            lower_g= np.array([40, 50, 0])\n",
    "            upper_g = np.array([80, 255, 255])\n",
    "\n",
    "            #red colorspace\n",
    "            lower_r1 = np.array([0, 80, 0])\n",
    "            upper_r1 = np.array([10, 255, 255])\n",
    "\n",
    "            lower_r2 = np.array([170, 0, 20])\n",
    "            upper_r2 = np.array([180, 255, 255])\n",
    "\n",
    "            # green mask\n",
    "            self.mask_g = cv.inRange(self.hsv_color, lower_g, upper_g)\n",
    "            \n",
    "            # red mask\n",
    "            mask_r1 = cv.inRange(self.hsv_color, lower_r1, upper_r1)\n",
    "            mask_r2 = cv.inRange(self.hsv_color, lower_r2, upper_r2)\n",
    "            self.mask_r = mask_r1 | mask_r2\n",
    "        else:\n",
    "            print(\"No image loaded.\")\n",
    "\n",
    "    def detect(self, mask, min_area, color, description):\n",
    "        contours, _ = cv.findContours(mask, cv.RETR_EXTERNAL, cv.CHAIN_APPROX_SIMPLE)\n",
    "        for cnt in contours:\n",
    "            if cv.contourArea(cnt) > min_area:\n",
    "                x, y, w, h = cv.boundingRect(cnt)\n",
    "                position = x + w // 2\n",
    "                cv.rectangle(self.image, (x, y), (x + w, y + h), color, 2)\n",
    "                cv.putText(self.image, f\"{description} BUOY\", (x, y - 10), cv.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "                return (True, position, x, y, w, h)\n",
    "        return False\n",
    "    \n",
    "    def distance_between(self, x_green, x_red, y_green, y_red, green_w, green_h, red_w, red_h):\n",
    "        green_point = ((x_green + (green_w // 2)), (y_green + (green_h // 2)))\n",
    "        red_point = ((x_red + (red_w // 2)), (y_red + (red_h // 2)))\n",
    "        distance = x_green - x_red\n",
    "        self.middle_x = abs((x_green - x_red) // 2)\n",
    "        center_line = (((x_green + (green_w // 2)) + (x_red + (red_w // 2))) // 2, ((y_green + (green_h // 2)) + (y_red + (red_h // 2))) // 2)\n",
    "        if distance < 0:\n",
    "            cv.line(self.image, green_point, red_point, (0, 255, 255), 2)\n",
    "            cv.circle(self.image, center_line, 5, (0, 255, 255), -1)\n",
    "        else:\n",
    "            cv.line(self.image, green_point, red_point, (0, 0, 255), 2)\n",
    "            cv.circle(self.image, center_line, 10, (0, 0, 255), -1)\n",
    "        cv.line(self.image, center_line,(((x_green + (green_w // 2)) + (x_red + (red_w // 2))) // 2, self.height // 2), (128,0,128),1)\n",
    "        cv.line(self.image,(((x_green + (green_w // 2)) + (x_red + (red_w // 2))) // 2, self.height // 2),(self.width // 2, self.height // 2), (128,0,128),1)\n",
    "\n",
    "    def detect_buoys(self, min_area = 1000):\n",
    "\n",
    "        green_detected, green_position, green_x, green_y, green_w, green_h = self.detect(self.mask_g, min_area, (0, 255, 0),\"GREEN\") if self.detect(self.mask_g, min_area, (0, 255, 0), \"GREEN\") else (False, None)\n",
    "        red_detected, red_position, red_x, red_y, red_w, red_h = self.detect(self.mask_r, min_area, (0, 0, 255),\"RED\") if self.detect(self.mask_r, min_area, (0, 0, 255), \"RED\") else (False, None)\n",
    "        \n",
    "        height, width, _ = self.image.shape\n",
    "        self.height = height\n",
    "        self.width = width\n",
    "\n",
    "        self.distance_between(green_x, red_x, green_y, red_y,green_w, green_h, red_w, red_h)\n",
    "        \n",
    "        middle_frame = width // 2\n",
    "        distance = middle_frame - self.middle_x\n",
    "\n",
    "        if green_detected and red_detected:\n",
    "            if green_position < width // 2 and red_position > width // 2:\n",
    "                self.text_size(width,\"Turn Around!\")\n",
    "            elif green_position > width // 2 and red_position < width // 2:\n",
    "                self.text_size(width,\"Keep course!\")\n",
    "        elif green_detected:\n",
    "            self.text_size(width,\"Turn Port!\")\n",
    "        elif red_detected:\n",
    "            self.text_size(width,\"Turn Starboard!\")\n",
    "        else:\n",
    "            self.text_size(width,\"Stop!\")\n",
    "        return None\n",
    "    \n",
    "    def run_on_video(self, output_path):\n",
    "        width = int(self.video.get(cv.CAP_PROP_FRAME_WIDTH))\n",
    "        height = int(self.video.get(cv.CAP_PROP_FRAME_HEIGHT))\n",
    "        fps = self.video.get(cv.CAP_PROP_FPS)\n",
    "\n",
    "        fourcc = cv.VideoWriter_fourcc(*'mp4v')\n",
    "        out = cv.VideoWriter(output_path, fourcc, fps, (width, height))\n",
    "\n",
    "        try:\n",
    "            while self.video.isOpened():\n",
    "                ret, frame = self.video.read()\n",
    "                if not ret:\n",
    "                    break\n",
    "                self.image = frame\n",
    "                self.generate_masks()\n",
    "                self.detect_buoys()\n",
    "                out.write(self.image)\n",
    "                cv.imshow(\"Processed Frame\", self.image)\n",
    "                if cv.waitKey(1) & 0xFF == ord('q'):\n",
    "                    break\n",
    "        \n",
    "        finally:\n",
    "            self.video.release()\n",
    "            out.release()\n",
    "            cv.destroyAllWindows()\n",
    "\n",
    "        return output_path"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ede5313",
   "metadata": {},
   "source": [
    "## Files in readable format"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7be5be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# video\n",
    "red_green = cv.VideoCapture('/home/salvador_cb/3_term/engineering_club/data/Videos/Bouygs in the sea.mp4')\n",
    "green = cv.VideoCapture('/home/salvador_cb/3_term/engineering_club/data/Videos/video with only green bouyg.mp4')\n",
    "red = cv.VideoCapture('/home/salvador_cb/3_term/engineering_club/data/Videos/video with only red bouyg.mp4')\n",
    "empty = cv.VideoCapture('/home/salvador_cb/3_term/engineering_club/data/Videos/empty sea.mp4')\n",
    "\n",
    "simulation = cv.VideoCapture('/home/salvador_cb/3_term/engineering_club/data/Videos/path 2.mp4')\n",
    "\n",
    "output = \"/home/salvador_cb/3_term/engineering_club/data/output/output.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e579e5",
   "metadata": {},
   "source": [
    "## Main"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "d586ab10",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 6, got 2)",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mValueError\u001b[39m                                Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[66]\u001b[39m\u001b[32m, line 4\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[34m__name__\u001b[39m == \u001b[33m\"\u001b[39m\u001b[33m__main__\u001b[39m\u001b[33m\"\u001b[39m:\n\u001b[32m      3\u001b[39m     nav = visionNav(video=simulation)\n\u001b[32m----> \u001b[39m\u001b[32m4\u001b[39m     \u001b[43mnav\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrun_on_video\u001b[49m\u001b[43m(\u001b[49m\u001b[43moutput_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43moutput\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 114\u001b[39m, in \u001b[36mvisionNav.run_on_video\u001b[39m\u001b[34m(self, output_path)\u001b[39m\n\u001b[32m    112\u001b[39m \u001b[38;5;28mself\u001b[39m.image = frame\n\u001b[32m    113\u001b[39m \u001b[38;5;28mself\u001b[39m.generate_masks()\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdetect_buoys\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    115\u001b[39m out.write(\u001b[38;5;28mself\u001b[39m.image)\n\u001b[32m    116\u001b[39m cv.imshow(\u001b[33m\"\u001b[39m\u001b[33mProcessed Frame\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28mself\u001b[39m.image)\n",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[64]\u001b[39m\u001b[32m, line 75\u001b[39m, in \u001b[36mvisionNav.detect_buoys\u001b[39m\u001b[34m(self, min_area)\u001b[39m\n\u001b[32m     72\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdetect_buoys\u001b[39m(\u001b[38;5;28mself\u001b[39m, min_area = \u001b[32m1000\u001b[39m):\n\u001b[32m     74\u001b[39m     green_detected, green_position, green_x, green_y, green_w, green_h = \u001b[38;5;28mself\u001b[39m.detect(\u001b[38;5;28mself\u001b[39m.mask_g, min_area, (\u001b[32m0\u001b[39m, \u001b[32m255\u001b[39m, \u001b[32m0\u001b[39m),\u001b[33m\"\u001b[39m\u001b[33mGREEN\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.detect(\u001b[38;5;28mself\u001b[39m.mask_g, min_area, (\u001b[32m0\u001b[39m, \u001b[32m255\u001b[39m, \u001b[32m0\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mGREEN\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m---> \u001b[39m\u001b[32m75\u001b[39m     red_detected, red_position, red_x, red_y, red_w, red_h = \u001b[38;5;28mself\u001b[39m.detect(\u001b[38;5;28mself\u001b[39m.mask_r, min_area, (\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m255\u001b[39m),\u001b[33m\"\u001b[39m\u001b[33mRED\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.detect(\u001b[38;5;28mself\u001b[39m.mask_r, min_area, (\u001b[32m0\u001b[39m, \u001b[32m0\u001b[39m, \u001b[32m255\u001b[39m), \u001b[33m\"\u001b[39m\u001b[33mRED\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m (\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m     77\u001b[39m     height, width, _ = \u001b[38;5;28mself\u001b[39m.image.shape\n\u001b[32m     78\u001b[39m     \u001b[38;5;28mself\u001b[39m.height = height\n",
      "\u001b[31mValueError\u001b[39m: not enough values to unpack (expected 6, got 2)"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    \n",
    "    nav = visionNav(video=simulation)\n",
    "    nav.run_on_video(output_path=output)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".ec_vision",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
